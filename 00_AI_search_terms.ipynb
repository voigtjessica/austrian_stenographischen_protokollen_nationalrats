{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00_AI_search_terms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "- First import a corpus made from normative documents related to data and artfitial inteligence from Austria, Germany and EU , all of them in German\n",
    "- Then removed the stopwords, based on a stopword list created from normative documents\n",
    "- selected all the words with frequence > 100\n",
    "- removed frequent words not related to data and artfitial inteligence\n",
    "- got only 7 words, which I thought it was too little\n",
    "- asked the chat GPT to give me a list of 50 most frequent words in german related to Data, AI and MAchine LEarning\n",
    "- removed the words considered too technical or that could be ambiguous with other theme\n",
    "- get a final list of 52 terms for search\n",
    "\n",
    "## Description\n",
    "The first step involved importing a corpus made up of normative documents related to data and artificial intelligence from Austria, Germany, and the European Union, all of which were in German. After importing the corpus, the next step was to remove stopwords based on a stopword list created from normative documents. Following this, all words with a frequency of less than 100 were selected, and frequent words not related to data and artificial intelligence were removed. However, after this process, only seven words remained, which was deemed insufficient. To expand the list of relevant terms, the researcher consulted Chat GPT to provide a list of the 50 most frequent words in German related to Data, AI, and Machine Learning. This list was further refined by removing technical terms and ambiguous words that could be interpreted as relating to other themes. The final list consisted of 52 terms that were deemed relevant for the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Importing automatically all json files :)\n",
    "\n",
    "dir_path = \"C:/Users/JVoigt/OneDrive - Universität für Weiterbildung Krems/Dokumente/Python Scripts/austrian_stenographischen_protokollen_nationalrats/datei\"\n",
    "\n",
    "for file_name in os.listdir(dir_path):\n",
    "    if file_name.endswith('.json'):\n",
    "        name = file_name[:-5]\n",
    "        file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "    \n",
    "    globals()[name] = pd.DataFrame(json_data)\n",
    "\n",
    "d = ['digitale_aktionsplan_at', 'nationale_ki_strategie_2023_addendum_at', 'nationale_ki_strategie_2023']\n",
    "at_concatenado = at_concatenado[at_concatenado['documento'].isin(d)]\n",
    "\n",
    "d = ['nationale_datenstrategie','nationale_ki_strategie_addendum', 'nationale_ki_strategie']\n",
    "de_concatenado = de_concatenado[de_concatenado['documento'].isin(d)]\n",
    "\n",
    "d = ['Daten-Governance-Rechtsakt', 'Data Act', 'eu_digital_markets_act', 'eu_horizon', 'eu_regulation_ai']\n",
    "eu_laws_concatenado = eu_laws_concatenado[eu_laws_concatenado['gesetzt'].isin(d)]\n",
    "\n",
    "# Importing automatically all the stopwords files\n",
    "dir_path = \"C:/Users/JVoigt/OneDrive - Universität für Weiterbildung Krems/Dokumente/Python Scripts/austrian_stenographischen_protokollen_nationalrats/datei/stopwords\"\n",
    "\n",
    "stopwords = []\n",
    "\n",
    "for file_name in os.listdir(dir_path):\n",
    "    if file_name.endswith('.json'):\n",
    "        file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "    \n",
    "    stopwords.extend(json_data)\n",
    "\n",
    "# abrir arquivos de leis concatenados\n",
    "# remover as stopwords\n",
    "# verificar os termos mais frequentes (quantos?)\n",
    "\n",
    "x = eu_laws_concatenado.text.tolist()\n",
    "y = at_concatenado.corpus.tolist()\n",
    "z = de_concatenado.corpus.tolist()\n",
    "\n",
    "#criando um grande corpus:\n",
    "corpus = ''.join(x + y + z)\n",
    "corpus = re.sub(r'[^a-zA-Zöüäß\\s]', '', corpus)\n",
    "\n",
    "# deixando tudo minúsculo:\n",
    "stopwords = [word.lower() for word in stopwords]\n",
    "corpus = corpus.lower()\n",
    "\n",
    "palavras = corpus.split()\n",
    "palavras_sem_stopwords = [palavra for palavra in palavras if palavra not in stopwords]\n",
    "\n",
    "# # corpus_sem_stopwords\n",
    "freq = dict(Counter(palavras_sem_stopwords))\n",
    "most_freq = {chave: valor for chave, valor in freq.items() if valor > 100}\n",
    "most_freq = {chave: valor for chave, valor in most_freq.items() if len(chave) >= 2}\n",
    "most_freq = list(most_freq.keys())\n",
    "\n",
    "# I removed the terms that couls relate to other themes, such as \"Architektur\"\n",
    "\n",
    "search_terms = ['daten', 'digitale', 'digitalen', 'torwachter', 'intelligenz', 'data', 'ki']\n",
    "\n",
    "# It was too little, so O asked the chat GPT to give me a list of 50 most frequent words in german related to Data, AI and MAchine LEarning\n",
    "\n",
    "chat_gpt_terms = ['Algorithmus', 'Big Data', 'Clustering', 'Datenbank', 'Datenaufbereitung', \n",
    "                  'Datenintegration', 'Datenmodellierung', 'Datenvisualisierung', 'Entscheidungsbaum', \n",
    "                  'Klassifizierung', 'Künstliche neuronale Netze', 'Lernrate', 'Lineare Regression', \n",
    "                  'Machine Learning', 'Machine-Learning','Machine-Learning-Modell', 'Modellvalidierung', 'Neuronales Netzwerk',\n",
    "                   'NLP', 'Natural Language Processing', 'Predictive Modeling', 'Regression', 'Reinforcement Learning',\n",
    "                   'Supervised Learning', 'Support Vector Machine', 'SVM', 'Text Mining', 'Unsupervised Learning', \n",
    "                   'Daten-Engineering', 'Cloud-Computing', 'Edge Computing', 'Digitalisierung', 'Cybersecurity', 'IoT',\n",
    "                    'Internet of Things', 'Edge-Analyse', 'Blockchain', 'Robotic Process Automation', 'RPA', \n",
    "                    'Deep Learning', 'Natural Language Generation', 'NLG', 'Computer Vision', 'Automatisierung',\n",
    "                    'GPT', 'Generative Pre-trained Transformer']\n",
    "\n",
    "chat_gpt_terms = [term.lower() for term in chat_gpt_terms]\n",
    "\n",
    "search_terms = search_terms + chat_gpt_terms\n",
    "\n",
    "with open('search_terms.json', 'w') as f:\n",
    "    json.dump(search_terms, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daten',\n",
       " 'digitale',\n",
       " 'digitalen',\n",
       " 'torwachter',\n",
       " 'intelligenz',\n",
       " 'data',\n",
       " 'ki',\n",
       " 'algorithmus',\n",
       " 'big data',\n",
       " 'clustering',\n",
       " 'datenbank',\n",
       " 'datenaufbereitung',\n",
       " 'datenintegration',\n",
       " 'datenmodellierung',\n",
       " 'datenvisualisierung',\n",
       " 'entscheidungsbaum',\n",
       " 'klassifizierung',\n",
       " 'künstliche neuronale netze',\n",
       " 'lernrate',\n",
       " 'lineare regression',\n",
       " 'machine learning',\n",
       " 'machine-learning',\n",
       " 'machine-learning-modell',\n",
       " 'modellvalidierung',\n",
       " 'neuronales netzwerk',\n",
       " 'nlp',\n",
       " 'natural language processing',\n",
       " 'predictive modeling',\n",
       " 'regression',\n",
       " 'reinforcement learning',\n",
       " 'supervised learning',\n",
       " 'support vector machine',\n",
       " 'svm',\n",
       " 'text mining',\n",
       " 'unsupervised learning',\n",
       " 'daten-engineering',\n",
       " 'cloud-computing',\n",
       " 'edge computing',\n",
       " 'digitalisierung',\n",
       " 'cybersecurity',\n",
       " 'iot',\n",
       " 'internet of things',\n",
       " 'edge-analyse',\n",
       " 'blockchain',\n",
       " 'robotic process automation',\n",
       " 'rpa',\n",
       " 'deep learning',\n",
       " 'natural language generation',\n",
       " 'nlg',\n",
       " 'computer vision',\n",
       " 'automatisierung',\n",
       " 'gpt',\n",
       " 'generative pre-trained transformer']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda parte: filtrando os documentos pelo topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JVoigt\\AppData\\Local\\Temp\\ipykernel_17260\\2484155581.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_texts_filtered['founded_term'] = df_texts_filtered['topic'].apply(find_matching_term)\n",
      "C:\\Users\\JVoigt\\AppData\\Local\\Temp\\ipykernel_17260\\2484155581.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_texts_filtered['code_sitzung'] = df_texts_filtered['code_sitzung'].apply(lambda x: re.sub('/', '_', x))\n",
      "C:\\Users\\JVoigt\\AppData\\Local\\Temp\\ipykernel_17260\\2484155581.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_texts_filtered['date'] = df_texts_filtered['date'].apply(lambda x: re.sub('\\.|\\s', '_', x))\n",
      "C:\\Users\\JVoigt\\AppData\\Local\\Temp\\ipykernel_17260\\2484155581.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_texts_filtered['day'] = df_texts_filtered['date'].apply(lambda x: re.sub('(?<=)_.*', '', x))\n",
      "C:\\Users\\JVoigt\\AppData\\Local\\Temp\\ipykernel_17260\\2484155581.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_texts_filtered['month'] = df_texts_filtered['date'].apply(lambda x: re.sub('[^a-zA-Zäüöß]+', '', x))\n",
      "C:\\Users\\JVoigt\\AppData\\Local\\Temp\\ipykernel_17260\\2484155581.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_texts_filtered['year'] = df_texts_filtered['year'].astype(str)\n",
      "C:\\Users\\JVoigt\\AppData\\Local\\Temp\\ipykernel_17260\\2484155581.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_texts_filtered['year'] = df_texts_filtered['year'].apply(lambda x: re.sub('\\..*', '', x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>url</th>\n",
       "      <th>topic</th>\n",
       "      <th>url_speech</th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>name_clean</th>\n",
       "      <th>position</th>\n",
       "      <th>code_sitzung</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>code_speech</th>\n",
       "      <th>founded_term</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>3784</td>\n",
       "      <td>3784</td>\n",
       "      <td>http://www.parlament.gv.at/gegenstand/XXVII/NR...</td>\n",
       "      <td>top 18 verwendung von daten im öffentlichen se...</td>\n",
       "      <td>/dokument/XXVII/NRSITZ/167/A_-_17_45_18_002727...</td>\n",
       "      <td>TOP 18 Verwendung von Daten im öffentlichen S...</td>\n",
       "      <td>SPÖ</td>\n",
       "      <td>Doris Bures</td>\n",
       "      <td>Präsidentin des Nationalrates</td>\n",
       "      <td>167_NRSITZ</td>\n",
       "      <td>6__Juli_2022_</td>\n",
       "      <td>2022</td>\n",
       "      <td>167_A___17_45_18_00272709</td>\n",
       "      <td>daten</td>\n",
       "      <td>6</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>3785</td>\n",
       "      <td>3785</td>\n",
       "      <td>http://www.parlament.gv.at/gegenstand/XXVII/NR...</td>\n",
       "      <td>top 18 verwendung von daten im öffentlichen se...</td>\n",
       "      <td>/dokument/XXVII/NRSITZ/167/A_-_17_46_00_002727...</td>\n",
       "      <td>Abg. Mag. Corinna Scharzenberger (ÖVP), 167. ...</td>\n",
       "      <td>ÖVP</td>\n",
       "      <td>Corinna Scharzenberger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167_NRSITZ</td>\n",
       "      <td>6__Juli_2022_</td>\n",
       "      <td>2022</td>\n",
       "      <td>167_A___17_46_00_00272718</td>\n",
       "      <td>daten</td>\n",
       "      <td>6</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>3786</td>\n",
       "      <td>3786</td>\n",
       "      <td>http://www.parlament.gv.at/gegenstand/XXVII/NR...</td>\n",
       "      <td>top 18 verwendung von daten im öffentlichen se...</td>\n",
       "      <td>/dokument/XXVII/NRSITZ/167/A_-_17_51_31_002727...</td>\n",
       "      <td>Abg. Melanie Erasim, MSc (SPÖ), 167. Sitzung,...</td>\n",
       "      <td>SPÖ</td>\n",
       "      <td>Melanie Erasim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167_NRSITZ</td>\n",
       "      <td>6__Juli_2022_</td>\n",
       "      <td>2022</td>\n",
       "      <td>167_A___17_51_31_00272722</td>\n",
       "      <td>daten</td>\n",
       "      <td>6</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>3787</td>\n",
       "      <td>3787</td>\n",
       "      <td>http://www.parlament.gv.at/gegenstand/XXVII/NR...</td>\n",
       "      <td>top 18 verwendung von daten im öffentlichen se...</td>\n",
       "      <td>/dokument/XXVII/NRSITZ/167/A_-_17_55_30_002727...</td>\n",
       "      <td>Abg. Süleyman Zorba (Grüne), 167. Sitzung, XX...</td>\n",
       "      <td>GRÜNE</td>\n",
       "      <td>Süleyman Zorba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167_NRSITZ</td>\n",
       "      <td>6__Juli_2022_</td>\n",
       "      <td>2022</td>\n",
       "      <td>167_A___17_55_30_00272747</td>\n",
       "      <td>daten</td>\n",
       "      <td>6</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>4811</td>\n",
       "      <td>4811</td>\n",
       "      <td>http://www.parlament.gv.at/gegenstand/XXVII/NR...</td>\n",
       "      <td>top 2-4 unterstützung für digitale transformat...</td>\n",
       "      <td>/dokument/XXVII/NRSITZ/149/A_-_12_02_44_002636...</td>\n",
       "      <td>TOP 2-4 Unterstützung für digitale Transforma...</td>\n",
       "      <td>ÖVP</td>\n",
       "      <td>Wolfgang Sobotka</td>\n",
       "      <td>Präsident des Nationalrates</td>\n",
       "      <td>149_NRSITZ</td>\n",
       "      <td>24__März_2022_</td>\n",
       "      <td>2022</td>\n",
       "      <td>149_A___12_02_44_00263699</td>\n",
       "      <td>digitale</td>\n",
       "      <td>24</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  index                                                url  \\\n",
       "3784        3784   3784  http://www.parlament.gv.at/gegenstand/XXVII/NR...   \n",
       "3785        3785   3785  http://www.parlament.gv.at/gegenstand/XXVII/NR...   \n",
       "3786        3786   3786  http://www.parlament.gv.at/gegenstand/XXVII/NR...   \n",
       "3787        3787   3787  http://www.parlament.gv.at/gegenstand/XXVII/NR...   \n",
       "4811        4811   4811  http://www.parlament.gv.at/gegenstand/XXVII/NR...   \n",
       "\n",
       "                                                  topic  \\\n",
       "3784  top 18 verwendung von daten im öffentlichen se...   \n",
       "3785  top 18 verwendung von daten im öffentlichen se...   \n",
       "3786  top 18 verwendung von daten im öffentlichen se...   \n",
       "3787  top 18 verwendung von daten im öffentlichen se...   \n",
       "4811  top 2-4 unterstützung für digitale transformat...   \n",
       "\n",
       "                                             url_speech  \\\n",
       "3784  /dokument/XXVII/NRSITZ/167/A_-_17_45_18_002727...   \n",
       "3785  /dokument/XXVII/NRSITZ/167/A_-_17_46_00_002727...   \n",
       "3786  /dokument/XXVII/NRSITZ/167/A_-_17_51_31_002727...   \n",
       "3787  /dokument/XXVII/NRSITZ/167/A_-_17_55_30_002727...   \n",
       "4811  /dokument/XXVII/NRSITZ/149/A_-_12_02_44_002636...   \n",
       "\n",
       "                                                   text  party  \\\n",
       "3784   TOP 18 Verwendung von Daten im öffentlichen S...    SPÖ   \n",
       "3785   Abg. Mag. Corinna Scharzenberger (ÖVP), 167. ...    ÖVP   \n",
       "3786   Abg. Melanie Erasim, MSc (SPÖ), 167. Sitzung,...    SPÖ   \n",
       "3787   Abg. Süleyman Zorba (Grüne), 167. Sitzung, XX...  GRÜNE   \n",
       "4811   TOP 2-4 Unterstützung für digitale Transforma...    ÖVP   \n",
       "\n",
       "                   name_clean                        position code_sitzung  \\\n",
       "3784              Doris Bures   Präsidentin des Nationalrates   167_NRSITZ   \n",
       "3785  Corinna Scharzenberger                              NaN   167_NRSITZ   \n",
       "3786          Melanie Erasim                              NaN   167_NRSITZ   \n",
       "3787          Süleyman Zorba                              NaN   167_NRSITZ   \n",
       "4811         Wolfgang Sobotka     Präsident des Nationalrates   149_NRSITZ   \n",
       "\n",
       "                date  year                code_speech founded_term day month  \n",
       "3784   6__Juli_2022_  2022  167_A___17_45_18_00272709        daten   6    07  \n",
       "3785   6__Juli_2022_  2022  167_A___17_46_00_00272718        daten   6    07  \n",
       "3786   6__Juli_2022_  2022  167_A___17_51_31_00272722        daten   6    07  \n",
       "3787   6__Juli_2022_  2022  167_A___17_55_30_00272747        daten   6    07  \n",
       "4811  24__März_2022_  2022  149_A___12_02_44_00263699     digitale  24    03  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_texts = pd.read_csv('C:\\\\Users\\\\JVoigt\\\\OneDrive - Universität für Weiterbildung Krems\\\\Dokumente\\\\Python Scripts\\\\austrian_stenographischen_protokollen_nationalrats\\\\df_texts_with_code_final.csv', sep=';', encoding='UTF-8')\n",
    "df_texts['topic'] = df_texts['topic'].str.lower()\n",
    "\n",
    "word_boundary_search_terms = [r\"\\b{}\\b\".format(term) for term in search_terms]\n",
    "pattern = re.compile(\"|\".join(word_boundary_search_terms))\n",
    "\n",
    "df_texts_filtered = df_texts[df_texts['topic'].apply(lambda x: bool(pattern.search(x)))]\n",
    "\n",
    "def find_matching_term(text):\n",
    "    for term in search_terms:\n",
    "        if re.search(r\"\\b{}\\b\".format(term), text):\n",
    "            return term\n",
    "    return None\n",
    "\n",
    "df_texts_filtered['founded_term'] = df_texts_filtered['topic'].apply(find_matching_term)\n",
    "df_texts_filtered['code_sitzung'] = df_texts_filtered['code_sitzung'].apply(lambda x: re.sub('/', '_', x))\n",
    "df_texts_filtered['date'] = df_texts_filtered['date'].apply(lambda x: re.sub('\\.|\\s', '_', x))\n",
    "df_texts_filtered['day'] = df_texts_filtered['date'].apply(lambda x: re.sub('(?<=)_.*', '', x))\n",
    "df_texts_filtered['month'] = df_texts_filtered['date'].apply(lambda x: re.sub('[^a-zA-Zäüöß]+', '', x))\n",
    "df_texts_filtered['year'] = df_texts_filtered['year'].astype(str)\n",
    "df_texts_filtered['year'] = df_texts_filtered['year'].apply(lambda x: re.sub('\\..*', '', x))\n",
    "\n",
    "# Adjusting dates:\n",
    "substituicoes = {'Juli': '07', 'März': '03', 'Dezember': '12', 'Juni': '06', 'April': '04', 'undFebruar': '02', 'November': '11'}\n",
    "df_texts_filtered=df_texts_filtered.replace({\"month\": substituicoes})\n",
    "\n",
    "#verificando palavras encontradas\n",
    "df_texts_filtered.groupby('founded_term').agg(total_found=('founded_term', len)).sort_values(by = 'total_found', ascending=False )\n",
    "\n",
    "df_texts_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['07', '03', '12', '06', '04', '02', '11'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_texts_filtered.month.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory to save the text files\n",
    "save_dir = r'C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\austrian_stenographischen_protokollen_nationalrats\\DNA_DB_at_speeches_filtered'\n",
    "\n",
    "# loop over the rows of the DataFrame\n",
    "for index, row in df_texts_filtered.iterrows():\n",
    "    # extract the text value\n",
    "    text = row['text']\n",
    "    \n",
    "    # extract the file name from the code_speech column\n",
    "    file_name = row['day'] + '.' + row['month'] + '.' + row['year'] + ' - ' + row['name_clean'] + ' - code ' + row['code_speech'] + ' - ' + row['code_sitzung'] +'.txt'\n",
    "    \n",
    "    # set the full path for the file\n",
    "    file_path = os.path.join(save_dir, file_name)\n",
    "    \n",
    "    # save the text to the file\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
